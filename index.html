<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="description" content="ShareGPT4V: Improving Large Multi-Modal Models with Better Captions">
    <meta name="keywords" content="GPT4-Vision">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>VCR-Bench</title>

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="index.css">
    <link rel="stylesheet" href="leaderboard.css">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
    <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.27.0/gradio.js"></script>
  </head>

  <style>
    .expandable-card .card-text-container {
      max-height: 200px;
      overflow-y: hidden;
      position: relative;
    }

    .expandable-card.expanded .card-text-container {
      max-height: none;
    }

    .expand-btn {
      position: relative;
      display: none;
      background-color: rgba(255, 255, 255, 0.8);
      /* margin-top: -20px; */
      /* justify-content: center; */
      color: #510c75;
      border-color: transparent;
    }

    .expand-btn:hover {
      background-color: rgba(200, 200, 200, 0.8);
      text-decoration: none;
      border-color: transparent;
      color: #510c75;
    }

    .expand-btn:focus {
      outline: none;
      text-decoration: none;
    }

    .expandable-card:not(.expanded) .card-text-container:after {
      content: "";
      position: absolute;
      bottom: 0;
      left: 0;
      width: 100%;
      height: 90px;
      background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
    }

    .expandable-card:not(.expanded) .expand-btn {
      margin-top: -40px;
    }

    .card-body {
      padding-bottom: 5px;
    }

    .vertical-flex-layout {
      justify-content: center;
      align-items: center;
      height: 100%;
      display: flex;
      flex-direction: column;
      gap: 5px;
    }

    .figure-img {
      max-width: 100%;
      height: auto;
    }

    .adjustable-font-size {
      font-size: calc(0.5rem + 2vw);
    }

    .chat-history {
      flex-grow: 1;
      overflow-y: auto;
      /* overflow-x: hidden; */
      padding: 5px;
      border-bottom: 1px solid #ccc;
      margin-bottom: 10px;
    }

    #gradio pre {
      background-color: transparent;
    }
  </style>

  <body>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">VCR-Bench:</h1>
              <h1 class="title is-2 publication-title"> Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning</h1>
             <br>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a style="font-weight:normal;">Yukun Qi<sup>1,2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Yiming Zhao<sup>1,2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Yu Zeng<sup>1,2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Xikun Bao<sup>1,2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Wenxuan Huang<sup>3</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://lin-chen.site/" style="font-weight:normal;">Lin Chen<sup>1*</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://lovesnowbest.site/" style="font-weight:normal;">Zehui Chen<sup>1</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Jie Zhao<sup>2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Zhongang Qi<sup>2</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.co.uk/citations?user=r6CvuOUAAAAJ&hl=en" style="font-weight:normal;">Feng Zhao<b><sup>&dagger;1</sup></b></a>,
                </span>

              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><b style="color:#00389A; font-weight:normal">&#x25B6 </b> <sup>1</sup> University of Science and Technology of China</span>
                <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> <sup>2</sup> Huawei Noah's Ark Lab</span>
                <br>
                <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> <sup>3</sup> East China Normal University</span>
              </div>
              
              <div class="is-size-6 publication-authors">
                <br>
                <span class="author-block"><b>*</b> Equal contribution.</span>
                <span class="author-block"><b>&dagger;</b> Corresponding authors.</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                    <span class="link-block">
                    <!-- TODO: change links -->
                      <a href="https://arxiv.org/pdf/2502.09621"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                    <span>Paper</span>
                    </a>
                  </span>
                  <!-- Paper Link.-->
                  <span class="link-block">
                    <a href="https://eccv.ecva.net/virtual/2024/poster/765" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arVix</span>
                    </a>
                  </span>
                  <!-- Code Link. -->
                  <span class="link-block">
                    <a href="https://github.com/zhishuifeiqian/VCR-Bench" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <!-- Dataset Link. -->
                  <span class="link-block">
                    <a href="https://huggingface.co/datasets/VLM-Reasoning/VCR-Bench"
                      class="external-link button is-normal is-rounded is-dark">
                      <span>ü§ó Dataset</span>
                    </a>
                  </span>
                  <!-- Leaderboard Link. -->
                  <span class="link-block">
                    <a href="https://vcr-bench.vercel.app/#leaderboard"
                      class="external-link button is-normal is-rounded is-dark">
                    <span>üèÜ Leaderboard</span>
                  </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section"  style="background-color:#efeff081" id="Abstract">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                The advancement of Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs) and large vision-language models (LVLMs).
                However, a rigorous evaluation framework for video CoT reasoning remains absent. Current video benchmarks fail to adequately assess the reasoning process and expose whether failures stem from deficiencies in perception or reasoning capabilities. 
                Therefore, we introduce VCR-Bench, a novel benchmark designed to comprehensively evaluate LVLMs‚Äô Video Chain-of-Thought Reasoning capabilities. VCR-Bench comprises 859 videos spanning a variety of video content and durations, along with 1,034 high-quality question-answer pairs. 
                Each pair is manually annotated with a stepwise CoT rationale, where every step is tagged to indicate its association with the perception or reasoning capabilities. Furthermore,we design seven distinct task dimensions and propose the CoT score to assess the entire CoT process based on the stepwise tagged CoT rationals.
                Extensive experiments on VCR-Bench highlight substantial limitations in current LVLMs. Even the top-performing model, o1, only achieves a 62.8% CoT score and an 56.7% accuracy, while most models score below 40%. 
                Experiments show most models score lower on perception than reasoning steps, revealing LVLMs‚Äô key bottleneck in temporal-spatial information processing for complex video reasoning.
                A robust positive correlation between the CoT score and accuracy confirms the validity of our evaluation framework and underscores the critical role of CoT reasoning in solving complex video reasoning tasks. We hope VCR-Bench to serve as a standardized evaluation framework and expose the actual drawbacks in complex video reasoning.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    
    <section class="section">
      <div class="container">
        
        <div class="columns is-centered">
          <div class="column is-full has-text-centered content">
            <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
            <div class="content">
              <table class="js-sort-table" id="results">
                <thead>
                  <tr>
                    <th rowspan="1" style="vertical-align: middle;"><strong>#</strong></th>
                    <th rowspan="1" style="vertical-align: middle;"><strong>Model</strong></th>
                  </tr>
                  <tr>
                    <th><strong>FTR</strong></th>
                    <th><strong>VTC</strong></th>
                    <th><strong>VTG</strong></th>
                    <th><strong>VKR</strong></th>
                    <th><strong>TSR</strong></th>
                    <th><strong>VPA</strong></th>
                    <th><strong>TSG</strong></th>
                    <th><strong>Avg</strong></th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>1</td>
                    <td><b class="best-score-text">Gemini-2.0-Flash ü•á</b></td>
                    <td><u>66.2</u></td>
                    <td><u>51.2</u></td>
                    <td><b>62.0</b></td>
                    <td>64.4</td>
                    <td><u>54.1</u></td>
                    <td><u>58.1</u></td>
                    <td><b>4.2</b></td>
                    <td><u>51.7</u></td>
                  </tr>
                  <tr>
                    <td>2</td>
                    <td><b class="best-score-text">Gemini-1.5-Pro ü•à</b></td>
                    <td>55.1</td>
                    <td>45.3</td>
                    <td>52.9</td>
                    <td>62.0</td>
                    <td>45.0</td>
                    <td>45.6</td>
                    <td>0.7</td>
                    <td>44.0</td>
                  </tr>
                  <tr>
                    <td>3</td>
                    <td><b class="best-score-text">o1 ü•â</b></td>
                    <td><b>66.7</b></td>
                    <td><b>52.2</b></td>
                    <td><u>56.9</u></td>
                    <td><b>74.3</b></td>
                    <td><b>61.0</b></td>
                    <td><b>60.2</b></td>
                    <td>0.0</td>
                    <td><b>56.7</b></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section" id="Performance">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">üìä Performance</h2>
        </div>
      </div>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <font color="#224baf" size=4><b>
            <p>
              We compare the performance of various large multi-modal models before and after replacing a corresponding portion of their SFT captions with those generated by GPT4-Vision:
            </p>
            <centering>
              <div style="text-align: center;">
                <img id="teaser" width="100%" src="images/performance_a.png">     
              </div>
            </centering>
            <br>
            <p>
              The remarkable performance of the proposed LMM, ShareGPT4V-7B, developed with the assistance of the ShareGPT4V dataset:
            </p>
            <centering>
              <div style="text-align: center;">
                <img id="teaser" width="45%" src="images/performance_b.png">     
              </div>
            </centering>
            </b></font>           
          </div>
        </div>
      </div>
    </section>

    <section class="section" style="background-color:#efeff081" id="examples">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Captioning and Conversation Examples</h2>
        </div>
      </div>
      <div class="container mt-5">
        <div class="form-row" style="justify-content: flex-end;">
          <div class="form-group col-md-1">
            <div class="col-md-2" style="width: 100%"><label>&nbsp;</label></div>
            <div class="btn-group" role="group" aria-label="Left and Right Controller"
              style="width: 100%;align-items: flex-end;justify-content: center;flex-direction: row;display: flex;">
              <button type="button" class="form-control btn btn-primary" id="prev-question"><i class="material-icons">keyboard_arrow_left</i></button>
              <button type="button" class="form-control btn btn-primary" id="next-question"><i class="material-icons">keyboard_arrow_right</i></button>
            </div>
          </div>
        </div>
        <div style="display: flex; justify-content: center; align-items: center;">
          <div class="card mb-4" style="width: 100%; display: flex; align-items: center;">
            <div class="card-body" id="selected-question" style="display: flex; height: 80vh;">
              <div class="chat-history">
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section" style="background-color:#efeff081" id="demo">
      <div class="container is-max-desktop" id="gradio">
        <!-- <gradio-app src="https://llava.hliu.cc"></gradio-app> TODO -->
      </div>
    </section>

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <p><b>
          If you find our work helpful for your research, please consider giving a citation üìÉ
        </b></p>
        <pre><code>
          @inproceedings{chen2024sharegpt4v,
            title={Sharegpt4v: Improving large multi-modal models with better captions},
            author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
            booktitle={European Conference on Computer Vision},
            pages={370--387},
            year={2024},
            organization={Springer}
          }
      </code></pre>
      </div>
    </section>

    <section class="section" id="Acknowledgement">
      <div class="container is-max-desktop content">
        <h2 class="title">Acknowledgement</h2>
        <p>
          This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a href="https://github.com/LLaVA-VL/llava-vl.github.io">LLaVA</a>, licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>.  We thank the LLaMA team for giving us access to their models, and open-source projects, including Alpaca and Vicuna.
        </p>

        <p>
          <b>Usage and License Notices</b>: The data, code and checkpoint is intended and licensed for research use only. They are also restricted to uses that follow the license agreement of CLIP,  LLaMA, Vicuna and GPT-4. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes.
        </p>
        <br>
        <centering>
          <div style="width: 30%; text-align: center;">
              <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=wNuAXemSTme55IF9obP1FzKoxfAcqTbRtJTs76zZJiQ"></script>
          </div>
        </centering>
      </div>
    </section>

    <script>
      // Handle message showing
      function createChatRow(sender, text, imageSrc) {
        var article = document.createElement("article");
        article.className = "media"

        var figure = document.createElement("figure");
        figure.className = "media-left";

        var span = document.createElement("span");
        span.className = "icon is-large";

        var icon = document.createElement("i");
        var img = document.createElement("img");

        if (sender === "User") {
          img.src = "images/user.png"
        }
        else if (sender === "ShareGPT4V-7B") {
          img.src = "images/logo.png"
        }
        else if (sender === "ShareGPT4V (100K)") {
          img.src = "images/logo.png"
        }
        else {
          img.src = "images/captioner.png"
        }
        icon.appendChild(img);

        var media = document.createElement("div");
        media.className = "media-content";

        var content = document.createElement("div");
        content.className = "content";

        var para = document.createElement("p");

        // wrap text in pre tag to preserve whitespace and line breaks
        var pre_text = document.createElement("pre");
        pre_text.style = "background-color: white; font-size: 18px; font-family: Arial; padding: 0; margin: 0; white-space: pre-wrap; word-wrap: break-word;";
        var paraText = document.createTextNode(text);
        pre_text.appendChild(paraText);

        var strong = document.createElement("strong");
        strong.innerHTML = sender;
        var br = document.createElement("br");

        para.appendChild(strong);
        para.appendChild(br);
        para.appendChild(pre_text);

        if (imageSrc) {
          var img = document.createElement("img");
          img.src = imageSrc;
          img.style = "max-width: 100%; max-height: 300px;"; // Adjust the style as needed
          para.appendChild(img);
        }

        content.appendChild(para);
        media.appendChild(content);
        span.appendChild(icon);
        figure.appendChild(span);
        if (sender !== "Description") {
          article.appendChild(figure);
        };
        article.appendChild(media);
        return article;
      }

      function addMessageToChatHistory(sender, message, imageSrc) {
        const chatHistory = document.querySelector('.chat-history');
        const chatRow = createChatRow(sender, message, imageSrc);
        chatHistory.appendChild(chatRow);
        chatHistory.scrollTop = chatHistory.scrollHeight;
      }

      function clearChatHistory() {
        const chatHistory = document.querySelector('.chat-history');
        chatHistory.innerHTML = "";
      }

      const conversations = [
      {
          "description": "multi-conv",
          "turns": [
            ["User", "", "images/examples/conv_case_3.png"],
            ["User", "What is the most common catchphrase of the character on the right?"],
            ["ShareGPT4V-7B",
              "The most common catchphrase of the character on the right is \"I am the one who knocks.\" This phrase is associated with the character Walter White from the TV show Breaking Bad, played by Bryan Cranston. Walter White is a methamphetamine manufacturer and distributor who is known for his intelligence, wit, and unpredictable behavior. The catchphrase is often used by Walter White to express his confidence and assertiveness, and it has become iconic in the series."
            ],
            ["User", "What kind of life would he have lived if he and Jesse Pinkman hadn't met?"],
            ["ShareGPT4V-7B",
              "If Walter White and Jesse Pinkman had never met, Walter White's life would have likely been very different. In the original timeline of the show, Walter White was a high school chemistry teacher who was diagnosed with cancer and decided to produce and sell methamphetamine to provide for his family after his death. He chose Jesse Pinkman, a former student and small-time criminal, as his partner in this venture." +
              "\n\nWithout Jesse, Walter would have had to find another partner or work alone to produce and distribute the methamphetamine. He might have had to rely on his own skills and knowledge to create the product and find customers. However, without Jesse's skills, connections, and resourcefulness, Walter's operation would likely have been smaller and less successful." +
              "\n\nAdditionally, without Jesse, Walter's character development would have been significantly altered. Jesse's presence and influence on Walter's life helped him to grow and change into the complex and morally ambiguous character that we see in the show. The relationship between Walter and Jesse is a central theme of Breaking Bad, and their dynamic drives much of the plot and character development."
            ]
          ]
        },
        {
          "description": "suitcases",
          "turns": [
            ["User", "", "images/examples/cap_case_3.png"],
            ["User", "Describe this image in detail."],
            ["Share-Captioner",
              "In the tranquil setting of a lush green lawn, three vintage suitcases, each a different size, are neatly arranged in a row. The smallest suitcase is positioned on the left, followed by the medium-sized one in the middle, and the largest suitcase on the right. Each suitcase is crafted from brown leather and features a sturdy brass handle on top, adding a touch of vintage charm to their appearance. \n\n" +
              "The suitcases are not alone in this scene. Behind them, a brick wall stands tall, providing a rustic backdrop to the scene. Nestled against this wall is a small tree, its branches reaching out as if to touch the suitcases. Adding a splash of color to the scene is a blue tarp, spread out on the ground in front of the wall.\n\n" +
              "The image captures a moment of stillness, with the suitcases waiting patiently for their next journey. The precise arrangement of the suitcases and their relative positions to each other and their surroundings create a harmonious composition that is pleasing to the eye."
            ]
          ]
        },
        {
          "description": "tower",
          "turns": [
            ["User", "", "images/examples/cap_case_1.png"],
            ["User", "Describe this image in detail."],
            ["Share-Captioner",
              "The image captures a serene scene at a waterfront. Dominating the left side of the frame is a tall, brown clock tower with a pointed roof. The tower is adorned with a clock face on each of its four sides, allowing time to be read from any direction.\n\n" +
              "Adjacent to the clock tower, on the right side of the image, is a green building with a curved roof. The building's green color contrasts with the brown of the clock tower, adding a splash of color to the scene.\n\n" + 
              "In the foreground, a body of water stretches out, reflecting the sky above and the buildings below. The water's surface is calm, mirroring the tranquility of the scene.\n\n" + 
              "In the background, beyond the clock tower and green building, construction cranes can be seen, hinting at ongoing development in the area. Despite this, the overall atmosphere of the image remains peaceful and serene."           
            ]
          ]
        },
        {
          "description": "reasoning",
          "turns": [
            ["User", "", "images/examples/conv_case_1.png"],
            ["User", "What is interesting in this image?"],
            ["ShareGPT4V-7B",
              "The interesting aspect of this image is the combination of a hand-drawn illustration of a child holding a bunch of grapes and the actual grapes placed on top of the drawing." + 
              " This creates a unique and creative visual effect, as the grapes appear to be floating above the child's head." + 
              " The image combines art and reality in a playful and imaginative way, making it visually appealing and engaging."  
            ]
          ]
        },
        {
          "description": "GPT4V",
          "turns": [
            ["User", "", "images/examples/cap_case_2.jpg"],
            ["User", "Can you describe the main features of this image for me?"],
            ["ShareGPT4V (100K)",
              "The image is a captivating oil painting titled \"The Sower\", created by the renowned artist Vincent Van Gogh. It\'s a beautiful representation of post-impressionism art. The painting vividly portrays a farmer in the act of sowing seeds in a field. The field, awash with hues of yellow and blue, forms a striking contrast against the farmer\'s figure. In the distance, a quaint village landscape unfolds, complete with houses and trees. The colors used are vibrant, bringing the scene to life with their intensity. The brushstrokes are clearly visible, adding texture and depth to the painting. This artwork is a testament to Van Gogh\'s fascination with the countryside and the simple, yet profound, peasant life. "
            ]
          ]
        },
        {
          "description": "analysis",
          "turns": [
            ["User", "", "images/examples/conv_case_2.png"],
            ["User", "From a photography perspective, analyze what makes this picture beautiful?"],
            ["ShareGPT4V-7B",
              "From a photography perspective, the image is beautiful due to the combination of elements and the play of light and shadow." +
              " The large hot air balloon, which is the main subject of the photo, is illuminated by a bright orange light, creating a striking contrast against the dark sky." +
              " The balloon's vibrant colors and the glowing light make it stand out prominently in the scene. \n\nThe setting is a sandy beach at night, which adds a sense of tranquility and serenity to the image." +
              " The silhouettes of people and vehicles in the foreground provide depth and context, indicating that the balloon is being prepared for a nighttime flight." +
              "The low angle of the shot enhances the grandeur of the balloon, making it appear larger and more majestic.\n\n" +
              " Overall, the image captures a unique moment of preparation and anticipation, with the hot air balloon as the centerpiece, set against a captivating nighttime backdrop." + 
              " The play of light and shadow, the contrasting colors, and the composition of the scene all contribute to the beauty of this photograph." +
              " It is a portrait painting that showcases the woman's enigmatic smile and has become one of the most famous and iconic art pieces in the world." +
              " The original work is displayed in the Louvre Museum in Paris, and it is known for its intricate details, use of oil paint, and the artist's innovative techniques that contributed to its enduring appeal and mystery."
            ]
          ]
        }
      ];

      let currentIndex = 0;

      function update_dialog_demo() {
        clearChatHistory();

        for (let i = 0; i < conversations[currentIndex].turns.length; i++) {
          if (conversations[currentIndex].turns[i].length == 2) {
            addMessageToChatHistory(conversations[currentIndex].turns[i][0], conversations[currentIndex].turns[i][1]);
          }
          else {
            addMessageToChatHistory(conversations[currentIndex].turns[i][0], conversations[currentIndex].turns[i][1], conversations[currentIndex].turns[i][2]);
          }
        }

        document.querySelector('.chat-history').scrollTop = 0;
      }

      // Initialize the displayed image
      update_dialog_demo();

      // Event listeners for the buttons
      document.getElementById('prev-question').addEventListener('click', () => {
        currentIndex = (currentIndex - 1 + conversations.length) % conversations.length;
        update_dialog_demo();
      });

      document.getElementById('next-question').addEventListener('click', () => {
        currentIndex = (currentIndex + 1) % conversations.length;
        update_dialog_demo();
      });
    </script>
  
  </body>

</html>